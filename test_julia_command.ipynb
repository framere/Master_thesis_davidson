{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1189d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x = [0.24151510186656056, 0.2859605256516444, 0.538593094993676, -0.09916096718721909, 0.16912000934013016]\n",
      "Residuals = Dict{Symbol, Any}(:reltol => 1.4901161193847656e-8, :abstol => 1.0e-8, :resnorm => [1.1774233324684862, 0.33886607402215163, 0.10030087180139968, 0.021253827651669555, 8.992579617258227e-17])\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using IterativeSolvers\n",
    "\n",
    "# Symmetric positive definite matrix\n",
    "n = 5\n",
    "A = Symmetric(randn(n, n))\n",
    "A += n * I\n",
    "\n",
    "# Right-hand side\n",
    "b = randn(n)\n",
    "\n",
    "# Solve Ax = b using Conjugate Gradient\n",
    "x, history = cg(A, b; abstol=1e-8, maxiter=100, log=true)\n",
    "\n",
    "println(\"Solution x = \", x)\n",
    "println(\"Residuals = \", history.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9febfa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 1.0  0.0\n",
       " 0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the identity matrix\n",
    "I_mat = Matrix{Float64}(I, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b17ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "# create a one dimensional array of random numbers\n",
    "x = rand(10)\n",
    "\n",
    "diff = zeros(length(x))\n",
    "for i in 1:length(x)\n",
    "    diff[i] = abs(x[i] - x[end])  # this will work as intended\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f152a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.5433695712637484\n",
       " 0.08802143835663323\n",
       " 0.467949932910234\n",
       " 0.08755455282303526\n",
       " 0.19441652079596394\n",
       " 0.10380590963512382\n",
       " 0.3254442926868497\n",
       " 0.0075988564832883965\n",
       " 0.10284311135775148\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c106e353",
   "metadata": {},
   "outputs": [
    {
     "ename": "Base.Meta.ParseError",
     "evalue": "ParseError:\n# Error @ /home/fmereto/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:78:15\n        # Julia's `repeat...until` loop\n        until k == maxorth || LinearAlgebra.norm(current_t_i) > η * old\n#             └────────────────────────────────────────────┘ ── Expected `end`",
     "output_type": "error",
     "traceback": [
      "ParseError:\n",
      "# Error @ /home/fmereto/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:78:15\n",
      "        # Julia's `repeat...until` loop\n",
      "        until k == maxorth || LinearAlgebra.norm(current_t_i) > η * old\n",
      "#             └────────────────────────────────────────────┘ ── Expected `end`\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:78"
     ]
    }
   ],
   "source": [
    "function select_corrections_ORTHO(ν, m, droptol, t_initial, V_initial)\n",
    "    # Algorithm 2: Selection of corrections (ORTHO)\n",
    "\n",
    "    # Choose 0 << η < 1;\n",
    "    # The pseudocode implies η is a parameter. Let's set a default or assume it's passed.\n",
    "    # A value like 0.5 is common for such conditions (half of the 'old' norm).\n",
    "    η = 0.5 \n",
    "\n",
    "    # Set n_b := 0; maxorth := 2;\n",
    "    n_b = 0\n",
    "    maxorth = 2\n",
    "\n",
    "    # Assuming t is a vector and V is a matrix (or a vector of vectors)\n",
    "    # The pseudocode implies t_initial is a starting vector for each iteration i.\n",
    "    # Let's assume t_initial is a function or an array that provides t_i for each i.\n",
    "    # For simplicity, we'll assume t_initial is a mutable vector that gets updated.\n",
    "    # If t_initial is meant to be different for each `i`, you'd need to provide that logic.\n",
    "    t = deepcopy(t_initial) # Make a mutable copy\n",
    "\n",
    "    # V_initial is used in the orthogonalization. Let's assume it's a matrix or a collection of vectors.\n",
    "    # The pseudocode uses v_j, so V_initial should be a collection of vectors v_1, ..., v_m.\n",
    "    # It also uses v_m+n_b, implying V grows.\n",
    "    V = [V_initial...] # Convert to a mutable array of vectors if V_initial is a matrix or similar\n",
    "\n",
    "    accepted_ts = [] # To store the accepted t_i vectors\n",
    "    accepted_vs = [] # To store the accepted v_m+n_b vectors (which are normalized t_i)\n",
    "\n",
    "    # for i := 1 : ν\n",
    "    for i in 1:ν\n",
    "        k = 0\n",
    "        \n",
    "        # We need a fresh t_i for each iteration of the outer loop.\n",
    "        # The pseudocode isn't explicit about how t_i is generated for each 'i'.\n",
    "        # For demonstration, let's assume `t` is re-initialized or passed in for each `i`.\n",
    "        # If `t` is meant to evolve across `i`, then `t = t_initial` should be outside the loop.\n",
    "        # Given the \"t_i := (I - v_j v_j^T)t_i\" part, it strongly suggests `t_i` is specific to the iteration.\n",
    "        # For this example, let's assume `t` is the vector currently being processed for the `i`-th iteration.\n",
    "        # You'll need to adapt this based on how your `t_i` is generated for each `i`.\n",
    "        \n",
    "        current_t_i = deepcopy(t) # Placeholder: you'll need to replace this with how your t_i is generated for each 'i'\n",
    "\n",
    "        repeat\n",
    "            old = LinearAlgebra.norm(current_t_i)\n",
    "            k += 1\n",
    "\n",
    "            # Orthogonalization: t_i := (I - v_j v_j^T)t_i for j := 1,...,m+n_b;\n",
    "            # Assuming v_j are column vectors. (v_j v_j^T) is an outer product.\n",
    "            # I - v_j v_j^T is a projection matrix.\n",
    "            \n",
    "            # The list of vectors to orthogonalize against is V (which initially contains V_initial)\n",
    "            # and then gets appended with new vectors `v_{m+n_b}`\n",
    "            \n",
    "            num_current_basis_vectors = m + n_b\n",
    "            \n",
    "            for j in 1:num_current_basis_vectors\n",
    "                if j <= length(V) # Check if V has enough elements\n",
    "                    v_j = V[j]\n",
    "                    \n",
    "                    # Ensure v_j is a column vector for outer product if it's not already\n",
    "                    if size(v_j, 2) != 1 && ndims(v_j) == 1\n",
    "                        v_j = reshape(v_j, :, 1)\n",
    "                    end\n",
    "                    \n",
    "                    # Projection: P = I - v_j * v_j'\n",
    "                    # t_i = P * t_i = t_i - (v_j * v_j') * t_i = t_i - v_j * (v_j' * t_i)\n",
    "                    # This is the Gram-Schmidt orthogonalization step.\n",
    "                    current_t_i = current_t_i - v_j * (v_j' * current_t_i)\n",
    "                else\n",
    "                    # This should ideally not happen if num_current_basis_vectors is managed correctly.\n",
    "                    # It means m + n_b is larger than the actual size of V.\n",
    "                    # This might indicate a misunderstanding of how V is structured.\n",
    "                    @warn \"Attempted to access v_j beyond the current size of V. Skipping orthogonalization for j=$j.\"\n",
    "                end\n",
    "            end\n",
    "        \n",
    "        # until k = maxorth or ||t_i|| > η * old;\n",
    "        # Julia's `repeat...until` loop\n",
    "        until k == maxorth || LinearAlgebra.norm(current_t_i) > η * old\n",
    "\n",
    "        # if ||t_i|| > droptol then {t_i is accepted}\n",
    "        if LinearAlgebra.norm(current_t_i) > droptol\n",
    "            n_b += 1\n",
    "            \n",
    "            # t̂_n_b := t_i / ||t_i||; vm+n_b := t̂_n_b\n",
    "            # Normalize t_i and store it as a new basis vector\n",
    "            normalized_t_i = current_t_i / LinearAlgebra.norm(current_t_i)\n",
    "            \n",
    "            push!(accepted_ts, current_t_i) # Store the accepted (unnormalized) t_i if needed\n",
    "            push!(V, normalized_t_i) # Add the normalized vector to our basis set V\n",
    "\n",
    "            # For consistency with the pseudocode where vm+n_b is assigned, we effectively update V.\n",
    "            # The pseudocode's \"vm+n_b := t̂_n_b\" implies V is being augmented.\n",
    "        end\n",
    "    end # endfor\n",
    "\n",
    "    return V, accepted_ts, n_b # Return the updated basis, accepted vectors, and final count\n",
    "end\n",
    "\n",
    "# --- Example Usage (Illustrative) ---\n",
    "\n",
    "using LinearAlgebra # For norm function\n",
    "\n",
    "# Define some dummy initial values for demonstration\n",
    "# In a real scenario, t_initial and V_initial would come from your specific problem.\n",
    "# Let's assume vectors are 3-dimensional.\n",
    "\n",
    "# Example: t_initial is a vector that changes or is generated per iteration `i`.\n",
    "# For simplicity, let's make it a fixed vector that is copied at the start of each `i` loop.\n",
    "# In a real application, you'd have a function `get_t_i(i)` or `t_initial_vectors[i]`.\n",
    "initial_t_vector_example = [1.0, 2.0, 3.0] \n",
    "\n",
    "# Example: V_initial contains 'm' initial orthogonal vectors (or basis vectors)\n",
    "m_example = 2\n",
    "V_initial_example = [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]] # Two orthogonal vectors\n",
    "\n",
    "ν_example = 5 # Number of outer iterations\n",
    "droptol_example = 1e-6 # A small tolerance value\n",
    "\n",
    "# Call the function\n",
    "updated_V, accepted_ts_list, final_n_b = select_corrections_ORTHO(\n",
    "    ν_example,\n",
    "    m_example,\n",
    "    droptol_example,\n",
    "    initial_t_vector_example,\n",
    "    V_initial_example\n",
    ")\n",
    "\n",
    "println(\"Final n_b: \", final_n_b)\n",
    "println(\"Number of accepted t's: \", length(accepted_ts_list))\n",
    "println(\"Number of vectors in updated V: \", length(updated_V))\n",
    "println(\"First few vectors in updated V:\")\n",
    "for i in 1:min(3, length(updated_V))\n",
    "    println(updated_V[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46a086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "y = [1, 2, 3, 4, 5]\n",
    "println(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cf51ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       " 2.0  3.0  4.0  5.0   6.0\n",
       " 3.0  4.0  5.0  6.0   7.0\n",
       " 4.0  5.0  6.0  7.0   8.0\n",
       " 5.0  6.0  7.0  8.0   9.0\n",
       " 6.0  7.0  8.0  9.0  10.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `norm` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing LinearAlgebra in the current active module Main",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `norm` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name may be made accessible by importing LinearAlgebra in the current active module Main\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W1sZmlsZQ==.jl:11"
     ]
    }
   ],
   "source": [
    "A = zeros(5, 5)\n",
    "for i in 1:5\n",
    "    for j in 1:5\n",
    "        A[i, j] = i + j\n",
    "    end\n",
    "end\n",
    "\n",
    "display(A)\n",
    "\n",
    "for i in 1:size(A, 1)\n",
    "    println(\"norm:\", norm(A[i, :]))\n",
    "    println(\"sum:\", sum(A[i, :]))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c128011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of non-convergent columns: [3, 4, 5]\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching zero(::Int64, ::Int64)\nThe function `zero` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  zero(!Matched::Type{Union{}}, ::Any...)\n   @ Base number.jl:310\n  zero(::Number)\n   @ Base number.jl:308\n  zero(!Matched::Type{LibGit2.GitHash})\n   @ LibGit2 ~/julia-1.11.4/share/julia/stdlib/v1.11/LibGit2/src/oid.jl:221\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching zero(::Int64, ::Int64)\n",
      "The function `zero` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  zero(!Matched::Type{Union{}}, ::Any...)\n",
      "   @ Base number.jl:310\n",
      "  zero(::Number)\n",
      "   @ Base number.jl:308\n",
      "  zero(!Matched::Type{LibGit2.GitHash})\n",
      "   @ LibGit2 ~/julia-1.11.4/share/julia/stdlib/v1.11/LibGit2/src/oid.jl:221\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:16"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "norms = zeros(size(A, 2))\n",
    "\n",
    "non_conv_indices = Int[]\n",
    "for i = 1:size(A, 2)\n",
    "    norms[i] = norm(A[:, i])\n",
    "    if norms[i] >= 13\n",
    "        push!(non_conv_indices, i)\n",
    "    end\n",
    "end\n",
    "println(\"Indices of non-convergent columns: \", non_conv_indices)\n",
    "\n",
    "red = size(A, 2) -2\n",
    "\n",
    "t = zero(size(A, 1), red)  # correction vectors\n",
    "\n",
    "for (i, idx) in enumerate(non_conv_indices)\n",
    "    t[:, i] = A[:, i] / norms[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7ce595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "B = zeros(size(A, 1), size(A, 2) - 3)\n",
    "println(size(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b0b076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Julia!\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello, Julia!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c3daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "println(collect(1:1:10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3217a617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "7\n",
      "10\n",
      "13\n",
      "16\n",
      "19\n",
      "22\n",
      "25\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for i in collect(1:3:30)\n",
    "    println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3602f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38217798244332446\n"
     ]
    }
   ],
   "source": [
    "println(rand())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4900376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse_matrix (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function sparse_matrix(N::Int, factor::Int)\n",
    "    A = zeros(Float64, N, N)\n",
    "    for i in 1:N\n",
    "        for j in 1:N\n",
    "            if i == j\n",
    "                A[i, j] = rand() * factor\n",
    "            else\n",
    "                if rand() < 0.05 # 5% chance to be non-zero off-diagonal --> Problemmm\n",
    "                    A[i, j] = rand() / factor\n",
    "                else\n",
    "                    # Keep the off-diagonal elements as zero\n",
    "                    A[i, j] = 0.0\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return Hermitian(A)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb975bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10 Hermitian{Float64, Matrix{Float64}}:\n",
       " 40.3653       0.0      0.0        …   0.00271354   0.0         0.0\n",
       "  0.0         31.6632   0.0            0.0          0.0         0.0\n",
       "  0.0          0.0     21.9434         0.0          0.0163261   0.0\n",
       "  0.0          0.0      0.0            0.0          0.0         0.0\n",
       "  0.0          0.0      0.0            0.0          0.0         0.0\n",
       "  0.00223808   0.0      0.0        …   0.0          0.0         0.0\n",
       "  0.0          0.0      0.0            0.0136667    0.0         0.0\n",
       "  0.00271354   0.0      0.0           45.9249       0.0         0.0\n",
       "  0.0          0.0      0.0163261      0.0         33.1983      0.0\n",
       "  0.0          0.0      0.0            0.0          0.0        35.759"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = sparse_matrix(10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df03f8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 40.36528080369829\n",
       " 31.663180955112196\n",
       " 21.943439909397767\n",
       " 41.033633157478015\n",
       " 18.3034661483998\n",
       " 40.33965585798469\n",
       " 11.181322411420712\n",
       " 45.92486958732117\n",
       " 33.19825747335109\n",
       " 35.75900908196829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diag(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2329ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Cannot set a non-diagonal index in a Hermitian matrix",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Cannot set a non-diagonal index in a Hermitian matrix\n",
      "\n",
      "Stacktrace:\n",
      " [1] setindex!(A::Hermitian{Float64, Matrix{Float64}}, v::Float64, i::Int64, j::Int64)\n",
      "   @ LinearAlgebra ~/julia-1.11.4/share/julia/stdlib/v1.11/LinearAlgebra/src/symmetric.jl:264\n",
      " [2] top-level scope\n",
      "   @ ~/Master_arbeit/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:12"
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "\n",
    "N = 2000\n",
    "factor = 10\n",
    "γ_pp = sparse_matrix(N, factor)\n",
    "\n",
    "# Replace small values with a threshold\n",
    "for i = 1:N\n",
    "    for j = 1:N\n",
    "        if abs(γ_pp[i,j] <= 1e-6)\n",
    "            γ_pp[i,j] = 1e-6\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "logabs_γ_pp = log10.(abs.(γ_pp))\n",
    "heatmap(logabs_γ_pp,\n",
    "        xlabel=\"b\",\n",
    "        ylabel=\"a\",\n",
    "        colorbar_title=\"color map\",\n",
    "        aspect_ratio=:equal,\n",
    "        c = :ice,\n",
    "        size = (800, 800))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
